{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def extract_msg(line):\n",
    "    \"Regex to extract datetime, sender and message.\"\n",
    "    date = []\n",
    "    msg = []\n",
    "    sender_name = []\n",
    "    datetime_pat  = \"\\d\\d\\d\\d\\-\\d\\d-\\d\\d,\\ \\d:\\d\\d:\\d\\d [a-zA-Z][a-zA-Z]\" \n",
    "    date = re.search(datetime_pat, line)\n",
    "\n",
    "    sender_pat = \"(?<=(\\])) [^:]*\" #\"\\-\\ \\w+\\:|\\-\\ \\w+\\ \\w+\\:\" # one or two names\n",
    "    sender = re.search(sender_pat,line)\n",
    "\n",
    "    if date and sender:\n",
    "        if len(sender.group(0)) < 25:\n",
    "            # assumes a name and last name is less than at most N chars. \n",
    "            # Avoids misclassifying a status change with a semi-colon for a name.\n",
    "            date = pd.to_datetime(date.group(0))        \n",
    "            sender_name = sender.group(0)[1:]\n",
    "\n",
    "            msg = line[line.index(sender_name)+len(sender_name)+2:]\n",
    "        \n",
    "    return date, sender_name, msg\n",
    "\n",
    "# parse the entire convo as a pd.dataframe\n",
    "\n",
    "f = open('WhatsApp_chat_12_01_2020/_chat.txt', 'r', encoding='utf-8')\n",
    "conv0 = pd.DataFrame(columns=['date','sender','message'])\n",
    "for count, line in tqdm(enumerate(f)):\n",
    "    date, sender, msg  = extract_msg(line)\n",
    "    if sender and msg:\n",
    "        temp_df = pd.Series({'date':date ,'sender':sender,'message':msg})\n",
    "        conv0 = conv0.append(temp_df, ignore_index=True)\n",
    "        \n",
    "f.close()\n",
    "\n",
    "# This can be long depending on length of convo, save processed dataframe for easy usage\n",
    "conv0.to_csv('WhatsApp_chat_12_01_2020/processed_chat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0.to_csv('WhatsApp_chat_12_01_2020/processed_chat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0.message.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total messages sent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have sent a total of {len(conv0)} Messages between {min(conv0.date)} and {max(conv0.date)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total number of messages sent per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages per harman\n",
    "\n",
    "counts = conv0['sender'].value_counts()/len(conv0)*100\n",
    "%matplotlib inline\n",
    "fig = counts.plot(kind=\"bar\", title=\"% Messages per person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret this next graph as \"This person has answered directly to this person this many times\". For example, Alice and Bob answer each other most often. For \"equal\" dialogue, the matrix should be symmetric along its diagonal. Interactions with oneself are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "names = []\n",
    "\n",
    "for count,sender in enumerate(conv0['sender'].unique()):\n",
    "    index[sender] = count\n",
    "    names.append(sender)\n",
    "\n",
    "\n",
    "interactions = np.zeros((len(index),len(index)))\n",
    "\n",
    "prev_sender = conv0['sender'].iloc[0]\n",
    "for jj in range(1,len(conv0)):\n",
    "    \n",
    "    current_sender = conv0['sender'].iloc[jj]\n",
    "    if prev_sender != current_sender:\n",
    "        interactions[index[prev_sender],index[current_sender]]+=1\n",
    "    \n",
    "    prev_sender = current_sender\n",
    "\n",
    "def plot_interactions(cm, classes,\n",
    "                      normalize=False,\n",
    "                      title='People Interactions',\n",
    "                      cmap=plt.cm.coolwarm):\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'f'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('This person interacts most with')\n",
    "    plt.xlabel('This person')\n",
    "\n",
    "plot_interactions(interactions,names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The longest monologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_sender = []\n",
    "max_spam = 0\n",
    "tmp_spam = 0\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    \n",
    "    current_sender = conv0['sender'].iloc[jj]\n",
    "    if current_sender == prev_sender:\n",
    "        tmp_spam += 1\n",
    "        if tmp_spam>max_spam:\n",
    "            max_spam = tmp_spam\n",
    "            max_spammer = current_sender\n",
    "    else:\n",
    "        tmp_spam = 0\n",
    "    \n",
    "    prev_sender = current_sender\n",
    "        \n",
    "print(\"The most spam is from %s with %d consecutive messages\" % (max_spammer,max_spam))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person who has sent the most gifs and stickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gifs_sent = {}\n",
    "stickers_sent = {}\n",
    "for sender in conv0['sender'].unique():\n",
    "    gifs_sent[sender] = 0\n",
    "    stickers_sent[sender] = 0\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    if conv0[\"message\"].iloc[jj] == \"‎GIF omitted\\n\":\n",
    "        gifs_sent[conv0['sender'].iloc[jj]] += 1\n",
    "    if conv0[\"message\"].iloc[jj] == \"‎sticker omitted\\n\":\n",
    "        stickers_sent[conv0['sender'].iloc[jj]] += 1\n",
    "\n",
    "\n",
    "gifs_pd  = pd.DataFrame.from_dict(gifs_sent,orient=\"index\")\n",
    "gifs_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "gifs_pd = gifs_pd.transpose().iloc[0]\n",
    "_ = gifs_pd.plot(kind='bar', legend = False, title=\"Most gifs sent\")\n",
    "plt.show()\n",
    "\n",
    "stickers_pd  = pd.DataFrame.from_dict(stickers_sent,orient=\"index\")\n",
    "stickers_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "stickers_pd = stickers_pd.transpose().iloc[0]\n",
    "_ = stickers_pd.plot(kind='bar', legend = False, title=\"Most stickers sent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lulz_sent = {}\n",
    "for sender in conv0['sender'].unique():\n",
    "    lulz_sent[sender] = 0\n",
    "\n",
    "lulz = [\"lol\",\"lmao\",\"lulz\",\"rofl\",\"lolol\"]\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    if any(x in conv0[\"message\"].iloc[jj].lower() for x in lulz):\n",
    "        lulz_sent[conv0['sender'].iloc[jj]] += 1\n",
    "\n",
    "lulz_pd  = pd.DataFrame.from_dict(lulz_sent,orient=\"index\")\n",
    "lulz_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "lulz_pd = lulz_pd.transpose().iloc[0]\n",
    "\n",
    "_ =lulz_pd.plot(kind='bar', legend = False, title = \"Most LuLz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigget Slacker (texts during work hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_txt_sent = {}\n",
    "for sender in conv0['sender'].unique():\n",
    "    work_txt_sent[sender] = 0\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    if (conv0[\"date\"].iloc[jj].hour > 8 and \n",
    "        conv0[\"date\"].iloc[jj].hour < 17 and \n",
    "        conv0[\"date\"].iloc[jj].isoweekday()<6):\n",
    "        work_txt_sent[conv0['sender'].iloc[jj]] += 1\n",
    "\n",
    "\n",
    "work_txt_pd  = pd.DataFrame.from_dict(work_txt_sent,orient=\"index\")\n",
    "work_txt_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "work_txt_pd = work_txt_pd.transpose().iloc[0]\n",
    "\n",
    "_ = work_txt_pd.plot(kind='bar', legend = False, title = \"Most texts during work hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The night owls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_txt_sent = {}\n",
    "for sender in conv0['sender'].unique():\n",
    "    night_txt_sent[sender] = 0\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    if conv0[\"date\"].iloc[jj].hour < 6:\n",
    "        night_txt_sent[conv0['sender'].iloc[jj]] += 1\n",
    "\n",
    "\n",
    "night_txt_pd  = pd.DataFrame.from_dict(night_txt_sent,orient=\"index\")\n",
    "night_txt_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "night_txt_pd = night_txt_pd.transpose().iloc[0]\n",
    "\n",
    "_ = night_txt_pd.plot(kind='bar', legend = False, title = \"Most texts between midnight and 6 am\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHY ARE WE YELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yelling_sent = {}\n",
    "for sender in conv0['sender'].unique():\n",
    "    yelling_sent[sender] = 0\n",
    "\n",
    "for jj in range(len(conv0)):\n",
    "    if conv0[\"message\"].iloc[jj].upper() == conv0[\"message\"].iloc[jj]:\n",
    "        yelling_sent[conv0['sender'].iloc[jj]] += 1\n",
    "\n",
    "\n",
    "yelling_pd  = pd.DataFrame.from_dict(yelling_sent,orient=\"index\")\n",
    "yelling_pd.sort_values(by=0,ascending=False, inplace=True)\n",
    "yelling_pd = yelling_pd.transpose().iloc[0]\n",
    "\n",
    "_ = yelling_pd.plot(kind='bar', legend = False, title = \"MOST YELLING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorldClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "# d = path.dirname(__file__)\n",
    "ignore_words = [\"<Media omitted>\\n\",'go',\"yeah\",\"Im\",\"I'm\",]\n",
    "\n",
    "# Read the whole text.\n",
    "text = ''\n",
    "for jj in range(len(conv0)):\n",
    "    \n",
    "    if not any(x in conv0[\"message\"].iloc[jj] for x in ignore_words):\n",
    "\n",
    "        text+=(conv0['message'].iloc[jj]).lower()\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Masked wordcloud\n",
    "================\n",
    "Using a mask you can generate wordclouds in arbitrary shapes.\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "# read the mask image\n",
    "# taken from\n",
    "# http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpg\n",
    "alice_mask = (np.array(Image.open(\"dbutt.jpg\")))\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_mask,\n",
    "               stopwords=stopwords)\n",
    "# generate word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(path.join(\"dbutt.png\"))\n",
    "\n",
    "# show\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(alice_mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
